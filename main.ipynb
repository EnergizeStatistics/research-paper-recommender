{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Research Paper Recommender #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tools ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from fnmatch import fnmatch\n",
    "from pathlib import PurePath\n",
    "\n",
    "import urllib.request # download files \n",
    "import subprocess # operating system command\n",
    "\n",
    "import re\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & unzip research paper dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset path\n",
    "working_dir = \"/home/lee/Documents/Datasets for GitHub/scholarly_paper_recommendation/\"\n",
    "\n",
    "# download file\n",
    "url = 'http://www.comp.nus.edu.sg/%7Esugiyama/SchRecData/20100825-SchPaperRecData.zip'  \n",
    "urllib.request.urlretrieve(url, working_dir+'20100825-SchPaperRecData.zip')\n",
    "\n",
    "# unzip file\n",
    "subprocess.run([\"unzip\", working_dir+\"20100825-SchPaperRecData.zip\", \"-d\", working_dir])  \n",
    "\n",
    "del url\n",
    "os.remove( working_dir+'20100825-SchPaperRecData.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the vectors that each represents a candidate paper to recommend ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_file_names_in_list(folder_name, pattern):\n",
    "    all_rec_name = []\n",
    "    for path, subdirs, files in os.walk(folder_name):\n",
    "        for name in files:\n",
    "            if fnmatch(name, pattern):\n",
    "                all_rec_name.append(PurePath(path, name))\n",
    "                \n",
    "    return all_rec_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the full path of all files in the paper directory\n",
    "all_paper_files = all_file_names_in_list(working_dir+'20100825-SchPaperRecData/RecCandidatePapersFV/', \"*_recfv.txt\")\n",
    "# list, convert PurePath object to string\n",
    "all_paper_files = [str(x) for x in all_paper_files]\n",
    "# list of tuples, [(paper id like \"P00-1001\", paper file full path), (paper id like \"P00-1002\", paper file full path)]\n",
    "all_paper_files = list(zip([x[117:125] for x in all_paper_files], all_paper_files))\n",
    "\n",
    "# structure of all_df_original (which is a list):\n",
    "# all_df_original[0] is a dataframe with 2 columns\n",
    "# token tfidf_weight\n",
    "# AAA 0.01\n",
    "all_df_original = [pd.read_csv(file, names=['token', 'tfidf_weight'], \\\n",
    "                 delim_whitespace=True, index_col=False, header=None) for file in list(zip(*all_paper_files))[1]]\n",
    "\n",
    "# list of dataframes\n",
    "# all_rec_paper[0] is dataframe with 1 column, token is column name\n",
    "# AAA\n",
    "# 0.01\n",
    "all_rec_paper = [x.set_index('token').transpose().rename_axis('', axis=\"columns\").reset_index(drop=True)\\\n",
    "                     for x in all_df_original]\n",
    "\n",
    "# for i in range(len(all_rec_paper)):\n",
    "#     if (all_rec_paper[i].columns[0] == 'a'):\n",
    "#         if (all_rec_paper[i].loc[0, 'a'] > 0.5):\n",
    "#             all_rec_paper[i].drop('a', axis=1, inplace=True)\n",
    "        \n",
    "del all_df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the vectors that each represents a researcher's interest ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a researcher's past published papers represent their research interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the full path of all files in the junior researcher directory\n",
    "all_researcher_files = all_file_names_in_list(working_dir+'20100825-SchPaperRecData/JuniorR/', \"*-?_fv.txt\")\n",
    "# list, convert PurePath object to string\n",
    "all_researcher_files = [str(x) for x in all_researcher_files]\n",
    "# list of tuples, the regex extracts the researcher id from path,\n",
    "# then [(researcher id like \"y1\", paper file full path), (researcher id like \"y2\", paper file full path)]\n",
    "all_researcher_files = list(zip([re.findall(re.escape(working_dir+\"20100825-SchPaperRecData/JuniorR/\")\\\n",
    "                                            +\"([^/]+)\"+re.escape(\"/\"), x)[0] for x in all_researcher_files],\\\n",
    "                                all_researcher_files))\n",
    "\n",
    "# list of dataframes\n",
    "# all_researcher_original[0] is a dataframe with 2 columns\n",
    "# token tf_weight\n",
    "# AAA 0.01\n",
    "all_researcher_original = [pd.read_csv(file, names=['token', 'tf_weight'], \\\n",
    "                 delim_whitespace=True, index_col=False, header=None) for file in list(zip(*all_researcher_files))[1]]\n",
    "# list of dataframes\n",
    "# all_researcher_paper[0] is dataframe with 1 column, token is column name\n",
    "# AAA\n",
    "# 0.01\n",
    "all_researcher_paper = [x.set_index('token').transpose().rename_axis('', axis=\"columns\").reset_index(drop=True)\\\n",
    "                     for x in all_researcher_original]\n",
    "\n",
    "del all_researcher_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"calculate cosine similarity based on formula from wikipedia\n",
    "    https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "    \"\"\"\n",
    "    try:\n",
    "        numerator =  np.sqrt(x.dot(y))\n",
    "    except AttributeError:\n",
    "        numerator = 0\n",
    "        \n",
    "    denominator = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    \n",
    "    try:\n",
    "        cosine_similarity = round(numerator/float(denominator), 3)\n",
    "    except ZeroDivisionError:\n",
    "        cosine_similarity = 0\n",
    "\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity scores between a researcher's interest and all candidate papers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_most_similar_papers_selected_researcher(n_most, researcher):\n",
    "    rec_score = dict()\n",
    "    \n",
    "    # find where the selected researcher is in the list all_researcher_paper\n",
    "    researcher_index = list(zip(*all_researcher_files))[0].index(researcher)\n",
    "    \n",
    "    for i in range(len(all_rec_paper)):\n",
    "        together = None\n",
    "        together = pd.concat([all_rec_paper[i], all_researcher_paper[researcher_index]], axis=0, join='inner')   \n",
    "        if (len(together.iloc[0, :]) > 0) & (len(together.iloc[1, :]) > 0):\n",
    "            rec_score[all_paper_files[i][0]] = cosine_similarity(together.iloc[0, :], together.iloc[1, :])\n",
    "        else:             \n",
    "            rec_score[all_paper_files[i][0]] = 0\n",
    "        \n",
    "    # multiple keys have the same value    \n",
    "    result_unordered = list((key, value) for key, value in rec_score.items() \\\n",
    "            if value in sorted(set(rec_score.values()), reverse=True)[:n_most])\n",
    "    result = sorted(result_unordered, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 recommended papers: [('P00-1017', 1509.163), ('P00-1042', 1375.749), ('P00-1027', 1225.655), ('P00-1011', 1025.755), ('P00-1004', 873.019)]\n"
     ]
    }
   ],
   "source": [
    "print(\"5 recommended papers for researcher y3: {}\".format(n_most_similar_papers_selected_researcher(5, 'y3')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
